"""
ingest.py
Pipeline dâ€™ingestion PRO : PDF -> Nettoyage -> Chunks -> VectorDB.
GÃ¨re le reset de la base et la tolÃ©rance aux pannes.
"""

import sys
import os
# Ajoute le dossier racine (parent) au chemin de recherche de Python
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

import shutil
from typing import List
from tqdm import tqdm  # Pour la barre de progression

from loguru import logger
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.document_loaders import PyPDFLoader
from langchain_openai import OpenAIEmbeddings
from langchain_community.vectorstores import Chroma

from config import (
    DOCUMENTS_DIR,
    CHROMA_DB_DIR,
    CHUNK_SIZE,
    CHUNK_OVERLAP,
    EMBEDDING_MODEL,
    OPENAI_API_KEY,
    CHROMA_COLLECTION_NAME,
)

def reset_vector_db() -> None:
    """
    Supprime la base de donnÃ©es existante pour repartir de zÃ©ro.
    C'est crucial pour Ã©viter les doublons lors des rÃ©-ingestions.
    """
    if os.path.exists(CHROMA_DB_DIR):
        try:
            shutil.rmtree(CHROMA_DB_DIR)
            logger.warning(f"ğŸ§¹ Ancienne base de donnÃ©es supprimÃ©e : {CHROMA_DB_DIR}")
        except Exception as e:
            logger.error(f"âŒ Impossible de supprimer l'ancienne DB : {e}")

def load_pdfs() -> List:
    """Charge tous les PDFs avec gestion d'erreurs et barre de progression."""
    if not os.path.exists(DOCUMENTS_DIR):
        raise ValueError(f"âŒ Dossier documents introuvable : {DOCUMENTS_DIR}")

    files = [f for f in os.listdir(DOCUMENTS_DIR) if f.lower().endswith(".pdf")]
    
    if not files:
        raise ValueError("âŒ Aucun document PDF trouvÃ©.")

    docs: List = []
    
    logger.info(f"ğŸ“‚ DÃ©couverte de {len(files)} fichiers PDF...")

    # Utilisation de TQDM pour une barre de progression pro
    for filename in tqdm(files, desc="Chargement des PDF"):
        file_path = os.path.join(DOCUMENTS_DIR, filename)
        
        try:
            loader = PyPDFLoader(file_path)
            file_docs = loader.load()
            
            # Nettoyage des mÃ©tadonnÃ©es pour l'UI
            clean_name = os.path.splitext(filename)[0].replace("_", " ").title()
            
            for d in file_docs:
                d.metadata["source"] = clean_name  # Nom joli pour l'UI
                d.metadata["filename"] = filename  # Nom technique
                
            docs.extend(file_docs)
            
        except Exception as e:
            logger.error(f"âš ï¸ Erreur lors du chargement de {filename} : {e}")
            continue

    logger.success(f"ğŸ“¥ {len(docs)} pages chargÃ©es au total.")
    return docs


def chunk_documents(docs: List) -> List:
    """
    DÃ©coupe intelligente : on essaie de ne pas couper les phrases en deux.
    """
    splitter = RecursiveCharacterTextSplitter(
        chunk_size=CHUNK_SIZE,
        chunk_overlap=CHUNK_OVERLAP,
        add_start_index=True,
        # SÃ©parateurs prioritaires : Paragraphe > Ligne > Phrase > Mots
        separators=["\n\n", "\n", ".", " ", ""] 
    )
    chunks = splitter.split_documents(docs)
    logger.success(f"ğŸ§© DÃ©coupage terminÃ© : {len(chunks)} fragments gÃ©nÃ©rÃ©s.")
    return chunks


def embed_and_store(chunks: List) -> None:
    """GÃ©nÃ¨re les embeddings et stocke dans Chroma."""
    logger.info("âš™ï¸ Initialisation du modÃ¨le d'Embeddings OpenAI...")

    embeddings = OpenAIEmbeddings(
        model=EMBEDDING_MODEL,
        api_key=OPENAI_API_KEY,
    )

    logger.info(f"ğŸ’¾ Indexation dans ChromaDB ({CHROMA_DB_DIR})...")
    
    # Batch processing automatique par Chroma
    Chroma.from_documents(
        documents=chunks,
        embedding=embeddings,
        collection_name=CHROMA_COLLECTION_NAME,
        persist_directory=CHROMA_DB_DIR,
    )
    
    logger.success("ğŸ Indexation terminÃ©e avec succÃ¨s !")


def run_ingestion() -> None:
    """Pipeline complet dâ€™ingestion (Reset -> Load -> Chunk -> Store)."""
    logger.info("ğŸš€ DÃ©marrage du pipeline d'ingestion Data Governance...")
    
    # 1. Nettoyage (Clean Slate)
    reset_vector_db()
    
    # 2. Chargement
    docs = load_pdfs()
    if not docs:
        logger.warning("Aucun document valide n'a Ã©tÃ© chargÃ©. ArrÃªt.")
        return

    # 3. DÃ©coupage
    chunks = chunk_documents(docs)
    
    # 4. Stockage
    embed_and_store(chunks)

    logger.success("ğŸ‰ Base de connaissance mise Ã  jour !")


if __name__ == "__main__":
    run_ingestion()
